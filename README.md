# Clinical Software Usability Scale (cSUS)

## Methodology
* Following the pattern established by the scoring of the established, pan-industry, Systems Usability Scale (SUS) 8, the questions are scored against a 5-point scale:

> Agree Strongly - Agree - Don’t Know - Disagree - Disagree Strongly

* The ‘axis’ of the questions is alternated in order to try to vary the ‘positive’ or ‘negative’ attitude that the question could be seen to have.

* The questions were created by the members of the CCIO and CIO Networks, during a plenary session at DHI CCIO Summer School 2015, and in ensuing discussions on this thread.

## The Clinical Software Usability Survey questions are:

1. **In my opinion, the software reduces the risk of clinical error**. (positive)

1. **Effective support for this software is hard to access in a clinically-appropriate timescale**. (negative)

1. **In my opinion, the software improves the quality of clinical care I can provide**. (positive)

1. **The quality of the interaction/consultation with the patient is adversely affected by the use of this software**. (negative)

1. **Using the software gives me the key information I need on patient’s history, diagnosed conditions and current care and treatment plan**. (positive)

## Notes
* Each question scores from 0 to 4 points, where 0 signifies a trait of the least usable system and 4 signifies a trait of the most usable system. Clearly, because the ‘axis’ of the questions is alternated, the mathematics of the scoring must be alternated too. It makes the scoring a little bit complicated, again this is how it’s done is the SUS so we followed suit.

* The points are summed to give a total for the cSUS score in which the minimum score is 0 and the maximum score is 20. They are then multiplied by a factor of 2.5 to give a score ranging from 0 to 50. The authors of SUS felt it necessary to include this multiplication step, which I believe is an unnecessary complication (and in fact, for those authors, resulted in completely avoidable confusion as to whether the SUS is a percentage 8), but we followed them in doing so in order to maintain compatibility/parity of weighting between SUS and cSUS.

* In total therefore we end up with a SUS score out of 100 and a cSUS score out of 50. The total score for the combined survey is 150.

* If you have any feedback or ways to improve the questions or methodology, then this would be a good place to discuss it. If making a suggestion to improve on of the questions, please supply a suggested alternative form of words, rather than just making a comment about the existing form of words.

## Links
* [cSUS on openhealthhub.org](https://openhealthhub.org/t/clinical-software-usability-questions/456)
* [cSUS on Medium](https://marcus-baw.medium.com/the-clinical-software-usability-scale-ea3cab8cd37d)
* [cSUS Webinar on Vimeo](https://vimeo.com/166190203 18)
* [cSUS on Twitter](https://twitter.com/marcus_baw/status/1334802940448690176)

## LICENSE
<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons Licence" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br /><span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text" property="dct:title" rel="dct:type">Clinical Software Usability Scale (cSUS)</span> by <a xmlns:cc="http://creativecommons.org/ns#" href="bawmedical.co.uk" property="cc:attributionName" rel="cc:attributionURL">Dr Marcus Baw</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>
